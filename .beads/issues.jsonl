{"id":"llm-consumer-research-1","title":"Sync repository with latest upstream","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-18T11:13:20.828257-07:00","updated_at":"2025-10-18T22:27:52.351425-07:00","closed_at":"2025-10-18T22:27:53.351425-07:00"}
{"id":"llm-consumer-research-10","title":"Implement dynamic persona filtering \u0026 generation backends","description":"Extend persona modules and orchestrator to support runtime filters, persona injection, and optional generated segments with validation.","notes":"Implemented persona_filters, persona_generations, and persona_injections across orchestrator with heuristic/openai generator and regression tests.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-19T13:16:58.228308-07:00","updated_at":"2025-10-19T13:43:26.919142-07:00","closed_at":"2025-10-19T13:43:27.919142-07:00","dependencies":[{"issue_id":"llm-consumer-research-10","depends_on_id":"llm-consumer-research-9","type":"blocks","created_at":"2025-10-19T13:16:58.229021-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-11","title":"Upgrade UI \u0026 CLI for persona slicing and generation","description":"Augment Gradio app and CLI to accept persona filters, dynamic definitions, and expose newly generated segments; update help and docs.","notes":"Extended CLI flags and Gradio advanced controls for dynamic persona slicing/generation plus README guidance.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-19T13:17:03.059842-07:00","updated_at":"2025-10-19T13:43:31.307946-07:00","closed_at":"2025-10-19T13:43:32.307946-07:00","dependencies":[{"issue_id":"llm-consumer-research-11","depends_on_id":"llm-consumer-research-10","type":"blocks","created_at":"2025-10-19T13:17:03.060769-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-12","title":"Design population spec integration","description":"Outline request-level population_spec structure, raking strategy, and merge precedence across persona inputs.","design":"Add PopulationSpec model with fields: base_group, filters, generations, injections, csv_path (optional), marginals (dict[str, dict[str, float\u003e]), raking {enabled,bool; mode:'lenient'|'strict'; iterations:int}. Orchestrator merges sources in order: explicit personas -\u003e persona_csv -\u003e persona_group -\u003e population_spec base -\u003e request filters/gens/injections -\u003e population_spec filters/gens/injections. Each spec component accepts weight_share. After combine_persona_buckets, apply raking if enabled using shared helper that respects mode. Metadata collects spec hash and raking summary.","notes":"Documented population_spec shape, merge precedence, and raking strategy.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-19T20:07:24.01137-07:00","updated_at":"2025-10-19T20:19:08.21324-07:00","closed_at":"2025-10-19T20:19:09.21324-07:00"}
{"id":"llm-consumer-research-13","title":"Implement population spec and raking","description":"Add PopulationSpec model, compose personas from spec in orchestrator, share raking helper reused by CSV builder.","notes":"Implemented PopulationSpec support, shared raking helper, orchestrator integration, and regression tests.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-19T20:07:28.512405-07:00","updated_at":"2025-10-19T20:19:12.714255-07:00","closed_at":"2025-10-19T20:19:13.714255-07:00","dependencies":[{"issue_id":"llm-consumer-research-13","depends_on_id":"llm-consumer-research-12","type":"blocks","created_at":"2025-10-19T20:07:28.513361-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-14","title":"Expose population spec via CLI/UI","description":"Extend simple_cli and Gradio to accept population spec files/JSON and surface raking toggles.","notes":"Extended simple_cli and Gradio controls to accept population specs alongside existing persona knobs.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-19T20:07:35.426916-07:00","updated_at":"2025-10-19T20:19:17.446926-07:00","closed_at":"2025-10-19T20:19:18.446926-07:00","dependencies":[{"issue_id":"llm-consumer-research-14","depends_on_id":"llm-consumer-research-13","type":"blocks","created_at":"2025-10-19T20:07:35.427877-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-15","title":"Document population spec workflow","description":"Update README with population_spec usage, examples for CLI/UI, and note raking behavior.","notes":"Documented population_spec usage, CLI/UI workflow, and CSV builder script.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-19T20:07:40.740652-07:00","updated_at":"2025-10-19T20:19:23.729536-07:00","closed_at":"2025-10-19T20:19:24.729536-07:00","dependencies":[{"issue_id":"llm-consumer-research-15","depends_on_id":"llm-consumer-research-14","type":"blocks","created_at":"2025-10-19T20:07:40.741585-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-16","title":"Design multi-question simulation support","description":"Outline schema changes to support multiple consumer questions per run, covering request/response shapes and backward compatibility.","design":"Add SimulationRequest.questions: List[str] to capture additional questions; default remains legacy single intent question. Introduce new models PersonaQuestionResult and QuestionAggregate; extend PersonaResult with question_results list and keep top-level distribution for first question. SimulationResponse gains questions: List[QuestionAggregate]. Orchestrator loops over question list, running elicitation per question, reusing anchor bank, and populates persona/question results plus metadata. Backwards compatibility: aggregate/per-person distribution refer to first question.","notes":"Documented multi-question schema, default-first behavior, and compatibility approach.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-19T22:06:56.412145-07:00","updated_at":"2025-10-19T22:16:35.390456-07:00","closed_at":"2025-10-19T22:16:36.390456-07:00"}
{"id":"llm-consumer-research-17","title":"Implement multi-question orchestration","description":"Extend orchestrator, elicitation, and models to run multiple questions per persona and return per-question results with tests.","notes":"Added multi-question loop in orchestrator, PersonaQuestionResult and QuestionAggregate models, updated responses, and regression tests.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-19T22:07:02.246609-07:00","updated_at":"2025-10-19T22:16:40.311619-07:00","closed_at":"2025-10-19T22:16:41.311619-07:00","dependencies":[{"issue_id":"llm-consumer-research-17","depends_on_id":"llm-consumer-research-16","type":"blocks","created_at":"2025-10-19T22:07:02.247531-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-18","title":"Update interfaces for multi-question runs","description":"Expose multi-question config in CLI, Gradio, and docs; ensure CSV builder/PopulationSpec interactions documented.","notes":"Exposed additional questions in CLI/Gradio/simple interface, updated README with usage guidance.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-19T22:07:07.508599-07:00","updated_at":"2025-10-19T22:16:46.480054-07:00","closed_at":"2025-10-19T22:16:47.480054-07:00","dependencies":[{"issue_id":"llm-consumer-research-18","depends_on_id":"llm-consumer-research-17","type":"blocks","created_at":"2025-10-19T22:07:07.509556-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-2","title":"Run setup and validation targets","notes":"Installed dependencies, ran ruff check and pytest; all passing.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-18T11:13:25.286289-07:00","updated_at":"2025-10-18T22:27:52.353515-07:00","closed_at":"2025-10-18T22:27:53.353515-07:00","dependencies":[{"issue_id":"llm-consumer-research-2","depends_on_id":"llm-consumer-research-1","type":"blocks","created_at":"2025-10-18T11:13:25.287209-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-3","title":"Implement interface contract targets","notes":"Added Makefile interface (setup/check/test/llm-live/deps-audit/all), introduced mypy \u0026 live golden tests, and documented config via .agents.yml.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-18T17:09:14.721811-07:00","updated_at":"2025-10-18T22:27:52.353956-07:00","closed_at":"2025-10-18T22:27:53.353956-07:00"}
{"id":"llm-consumer-research-4","title":"Prepare commit and update GitHub","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-18T17:09:17.258544-07:00","updated_at":"2026-01-20T21:28:13.264809-08:00","closed_at":"2026-01-20T21:28:13.264809-08:00","close_reason":"Committed and pushed feature work to branch; holding off on merge until requested.","dependencies":[{"issue_id":"llm-consumer-research-4","depends_on_id":"llm-consumer-research-3","type":"blocks","created_at":"2025-10-18T17:09:17.259495-07:00","created_by":"rohit"}]}
{"id":"llm-consumer-research-5","title":"README narrative overhaul","description":"Make README explain mission, ethos, and differentiators for synthetic consumer research platform.","notes":"README now reframed around mission, pipeline, and roadmap.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-18T22:27:52.354643-07:00","updated_at":"2025-10-18T22:29:04.069115-07:00","closed_at":"2025-10-18T22:29:05.069115-07:00"}
{"id":"llm-consumer-research-5w0","title":"Web UI: audience builder + run comparison","description":"Improve the React web UI so it feels like a research workbench: (1) audience builder mapping to PopulationSpec basics, (2) run history and baseline/variant comparison with metric deltas, (3) export of results.","status":"closed","priority":1,"issue_type":"feature","owner":"codex.agent@example.com","created_at":"2026-01-20T21:27:41.841685-08:00","created_by":"Codex Agent","updated_at":"2026-01-20T22:28:58.902227-08:00","closed_at":"2026-01-20T22:28:58.902227-08:00","close_reason":"UI workbench + mix-in segment shipped","comments":[{"id":1,"issue_id":"llm-consumer-research-5w0","author":"Codex Agent","text":"Shipped Web UI workbench improvements: run history (localStorage), baseline compare with deltas, exports (results JSON + respondents CSV), copyable run summary, mix-in niche audience (generated segment) controls with share slider, clearer panel context allocation labels, and a mismatch banner + restore-config action when viewing saved runs.\\n\\nGates: make check/test/llm-live; web_ui npm run lint/build.","created_at":"2026-01-21T06:28:44Z"}]}
{"id":"llm-consumer-research-6","title":"Enhance persona schema with richer participant context","description":"Extend PersonaSpec and ingestion sources to capture demographics, habits, and provenance so prompts and outputs reflect participant background.","notes":"Extended PersonaSpec schema, YAML library, and ingestion so panels carry background, habit, and channel details; prompts now surface the richer context.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-19T10:16:02.172853-07:00","updated_at":"2025-10-19T10:23:27.680835-07:00","closed_at":"2025-10-19T10:23:28.680835-07:00"}
{"id":"llm-consumer-research-7","title":"Simplify user-facing interface for synthetic surveys","description":"Design a streamlined entry point (CLI/Make target/API wrapper) so teams can run simulations with minimal setup, including sensible defaults and basic config exposure.","notes":"Added simple_interface helpers and a lightweight CLI so teammates can run simulations with one command, plus metadata summaries to make outputs easier to digest.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-19T10:16:05.647195-07:00","updated_at":"2025-10-19T10:23:31.902432-07:00","closed_at":"2025-10-19T10:23:32.902432-07:00"}
{"id":"llm-consumer-research-8","title":"Add regression guards for enriched personas and interface","description":"Update/extend unit tests and integration coverage for persona ingestion, prompt composition, and simplified interface to prevent regressions.","notes":"Expanded unit coverage for persona parsing, summaries, and the simplified interface to guard against regression.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-10-19T10:16:08.086337-07:00","updated_at":"2025-10-19T10:23:36.077636-07:00","closed_at":"2025-10-19T10:23:37.077636-07:00"}
{"id":"llm-consumer-research-9","title":"Design dynamic persona slicing \u0026 generation architecture","description":"Outline approach to extend persona pipeline for runtime filtering and LLM-backed generation, noting touchpoints across orchestrator, models, and UI.","design":"Introduce PersonaLibrary abstraction for loading YAML personas lazily with reload support. Extend SimulationRequest with persona_filters (list of field/value matchers), persona_injections (explicit PersonaSpec overrides), and persona_generation (prompt-driven synthesis spec). Add persona_generation module with heuristic generator (default) and OpenAI-backed generator (optional). Orchestrator composes personas from: explicit request.personas, filtered library personas, generated personas, CSV, and group. Provide ensure_weights to renormalize by requested weight shares. UI/CLI gain advanced controls to accept filter expressions, generation prompts, and JSON persona payloads.","notes":"Captured architecture for dynamic persona system and delivered implementation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-10-19T13:16:54.728782-07:00","updated_at":"2025-10-19T13:43:35.048678-07:00","closed_at":"2025-10-19T13:43:36.048678-07:00"}
{"id":"llm-consumer-research-e93","title":"Panel Builder: richer audience + behavioral profiles","description":"Extend Population construction beyond the current library + mix-in segment:\\n\\n- Map UI controls to full PopulationSpec (filters, injections, generations, optional raking)\\n- Let user paste/upload behavioral evidence (notes, transcripts, browser-history-like signals)\\n- Chunk/summarize evidence into per-panelist context with editable assignments\\n- Save/reuse a named panel config (seed + composition) for repeated experiments","status":"open","priority":1,"issue_type":"feature","owner":"codex.agent@example.com","created_at":"2026-01-20T22:28:28.653135-08:00","created_by":"Codex Agent","updated_at":"2026-01-20T22:28:28.653135-08:00","labels":["feature"]}
